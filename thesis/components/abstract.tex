\clearemptydoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Abstract}





\vspace*{2cm}
\begin{center}
{\Large \bf Abstract}
\end{center}
\vspace{1cm}

Deep Reinforcement Learning is a subfield of Machine Learning that uses deep neural networks to solve complex tasks without any previous knowledge of the system these tasks reside in.
A common problem in Reinforcement Learning today is called \emph{Exploration vs Exploitation}, meaning that on the one hand the algorithm has to exploit learned behaviors but one the other hand it also has to explore new ways to come up with better solutions.
In this thesis we will look at three very different, state of the art, Reinforcement Learning algorithms, add different extensions to them and compare them.
We will focus on the aspect of \emph{Exploration vs Exploitation} by adding different kinds of noise to each of these algorithms.
We will look at previous work done in this direction and also try out new ways to achieve better exploration.
The goal of this thesis is to give an overview of the current state of RL algorithms and provide ideas on how to enhance them.
