@misc{atari,
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and
    Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  title = {{Playing Atari with Deep Reinforcement Learning}},
  howpublished = {\url{https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf}},
  year = {2013},
  note = {Retrieved on 2017.09.10}
}

@misc{modelbasedmodelfree,
  author = {Quentin J. M. Huys and Anthony Cruickshank and Peggy Seriès},
  title = {{Reward-Based Learning, Model-Based and Model-Free}},
  howpublished = {\url{https://www.quentinhuys.com/pub/HuysEa14-ModelBasedModelFree.pdf}},
  year = {2014},
  note = {Retrieved on 2017.09.12}
}

@misc{curse_dimensionality,
  howpublished = {\url{https://en.wikipedia.org/wiki/Curse_of_dimensionality}},
  note = {Retrieved on 2017.10.25}
}

@misc{cmu_snake_robots_mexico,
  author = {Evan Ackerman},
  title = {{What CMU's Snake Robot Team Learned While Searching for Mexican Earthquake Survivors}},
  howpublished = {\url{https://spectrum.ieee.org/automaton/robotics/industrial-robots/cmu-snake-robot-mexico-earthquake}},
  year = {2017},
  note = {Retrieved on 2017.10.13}
}

@misc{backprop,
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald},
  title = {{Learning representations by back-propagating errors}},
  howpublished = {Nature. 323 (6088): 533–536. doi:10.1038/323533a0},
  year = {1986}
}

@misc{lecture_mdp,
  author = {David Silver},
  title = {{Lecture 2: Markov Decision Processes}},
  howpublished = {\url{http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MDP.pdf}},
  note = {Retrieved on 2017.09.10}
}

@misc{sarsa,
  author = {G. A. Rummery and M. Niranjan},
  title = {{On-Line Q-Learning Using Connectionist Systems}},
  howpublished = {\url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.2539&rep=rep1&type=pdf}},
  note = {Retrieved on 2017.09.16}
}

@misc{qlearning,
  author = {Christopher John Cornish Hellaby Watkins},
  title = {{Learning from Delayed Rewards}},
  howpublished = {\url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.2539&rep=rep1&type=pdf}},
  note = {Retrieved on 2017.09.16}
}

@misc{delta_rule,
  title = {{Delta rule}},
  howpublished = {\url{https://en.wikipedia.org/wiki/Delta_rule}},
  note = {Retrieved on 2017.09.18}
}

@misc{openai_gym,
        author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
        title = {{OpenAI Gym}},
        year = {2016},
        howpublished = {arXiv:1606.01540}
}

@misc{qlearning_proof,
  author = {Francisco S. Melo},
  title = {{Convergence of Q-learning: a simple proof}},
  howpublished = {\url{http://users.isr.ist.utl.pt/~mtjspaan/readingGroup/ProofQlearning.pdf}},
  note = {Retrieved on 2017.09.16}
}

@misc{dnn_go,
  author = {David Silver et al},
  title = {{Mastering the game of Go with deep neural networks and tree search}},
  howpublished = {Nature 529, 484–489 (28 January 2016)},
  note = {Retrieved on 2017.09.16}
}

@misc{policy_gradient_silver,
  author = {David Silver et al},
  title = {{Deterministic Policy Gradient Algorithms}},
  howpublished = {\url{http://proceedings.mlr.press/v32/silver14.pdf}},
  note = {Retrieved on 2017.09.19}
}

@misc{policy_gradient_sutton,
  author = {Richard S. Sutton and David McAllester and Satinder Singh and Yishay Mansour},
  title = {{Policy Gradient Methods for Reinforcement Learning with Function Approximation}},
  howpublished = {\url{https://homes.cs.washington.edu/~todorov/courses/amath579/reading/PolicyGradient.pdf}},
  note = {Retrieved on 2017.09.19}
}

@misc{universality_proof,
  author = {George Cybenko},
  title = {{Approximation by Superpositions of a Sigmoidal Function}},
  howpublished = {\url{http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=1E494139419C89420A3E84A62893B350?doi=10.1.1.441.7873&rep=rep1&type=pdf}},
  note = {Retrieved on 2017.09.19}
}

@misc{large_numbers,
  title = {{Law of large numbers}},
  howpublished = {\url{https://en.wikipedia.org/wiki/Law_of_large_numbers}},
  note = {Retrieved on 2017.09.19}
}

@misc{adam_optimizer,
  author = {Diederik P. Kingma and Jimmy Ba},
  title = {{Adam: A Method for Stochastic Optimization}},
  howpublished = {\url{https://arxiv.org/abs/1412.6980}},
  note = {Retrieved on 2017.09.13}
}

@misc{github_stars,
  title = {{Top Deep Learning Projects}},
  howpublished = {\url{https://github.com/aymericdamien/TopDeepLearning}},
  note = {Retrieved on 2017.09.13}
}

@misc{cnn_wiki,
  title = {{Convolutional neural network}},
  howpublished = {\url{https://en.wikipedia.org/wiki/Convolutional_neural_network#History}},
  note = {Retrieved on 2017.09.25}
}

@misc{tensorflow,
  author = {Martın Abadi et al},
  title = {{Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
  howpublished = {\url{http://download.tensorflow.org/paper/whitepaper2015.pdf}},
  note = {Retrieved on 2017.09.23}
}

@misc{per,
  author = {Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
  title = {{Prioritized Experience Replay}},
  howpublished = {\url{https://arxiv.org/pdf/1511.05952.pdf}},
  year = {2015},
  note = {Retrieved on 2017.09.25}
}

@misc{ddqn,
  author = {Hado van Hasselt and Arthur Guez and David Silver},
  title = {{Deep Reinforcement Learning with Double Q-learning}},
  howpublished = {\url{https://arxiv.org/abs/1509.06461}},
  year = {2015},
  note = {Retrieved on 2017.09.25}
}

@misc{duel_dqn,
  author = {Ziyu Wang and Tom Schaul and Matteo Hessel and Hado van Hasselt and Marc Lanctot and Nando de Freitas},
  title = {{Dueling Network Architectures for Deep Reinforcement Learning}},
  howpublished = {\url{https://arxiv.org/abs/1511.06581}},
  year = {2015},
  note = {Retrieved on 2017.09.25}
}

@misc{ddpg,
  author = {Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  title = {{Continuous control with deep reinforcement learning}},
  howpublished = {\url{https://arxiv.org/abs/1509.02971}},
  year = {2015},
  note = {Retrieved on 2017.09.26}
}

@misc{trpo,
  author = {John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
  title = {{Trust Region Policy Optimization}},
  howpublished = {\url{https://arxiv.org/abs/1502.05477}},
  year = {2015},
  note = {Retrieved on 2017.09.26}
}

@misc{param_noise,
  author = {Matthias Plappert and Rein Houthooft and Prafulla Dhariwal and Szymon Sidor and Richard Y. Chen and Xi Chen and Tamim Asfour and Pieter Abbeel and Marcin Andrychowicz},
  title = {{Parameter Space Noise for Exploration}},
  howpublished = {\url{https://arxiv.org/abs/1706.01905}},
  year = {2017},
  note = {Retrieved on 2017.09.26}
}

@misc{ppo,
  author = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  title = {{Proximal Policy Optimization Algorithms}},
  howpublished = {\url{https://arxiv.org/abs/1707.06347}},
  year = {2017},
  note = {Retrieved on 2017.10.07}
}

@Book{sutton,
   author = {Richard S. Sutton and Andrew G. Barto},
   title = {{Reinforcement Learning: An Introduction}},
   publisher = {The MIT Press},
   year = {2012},
   isbn = {9780262332767}
}

@Book{neuralnets,
   author = {David Kriesel},
   title = {{A brief Introduction to Neural Networks}},
   howpublished = {\url{http://users.isr.ist.utl.pt/~mtjspaan/readingGroup/ProofQlearning.pdf}},
   year = {2005}
}
